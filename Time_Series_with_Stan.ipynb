{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurauguc/bayesian_time_series/blob/main/Time_Series_with_Stan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Simulations\n",
        "\n",
        "Latest update: 2024-11-07"
      ],
      "metadata": {
        "id": "aLA5nWW_W6V0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of Contents\n",
        "\n",
        "1. [Introduction](#introduction)\n",
        "2. [Set-Up](#setup)\n",
        "3. [Background](#background)\n",
        "4. [Approach](#approach)\n",
        "5. [Implementation](#implementation)\n",
        "6. [Conclusion](#conclusion)"
      ],
      "metadata": {
        "id": "AVyEak3FZ-HQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction <a name=\"introduction\"></a>\n",
        "\n",
        "This notebook evaluates a Bayesian time series model built in Stan, comparing its predictions to those from a frequentist counterpart in Python’s `stats` library. The primary goal is educational: to understand the conditions under which Bayesian and frequentist predictions align and to deepen my understanding of the mathematical principles underlying time series modeling.\n",
        "\n",
        "By constructing this model in Stan, where each component—from the likelihood function to parameter distributions—is manually specified, I’ve gained valuable insights into Bayesian statistics and the fundamentals of time series analysis. A secondary objective of this notebook is to illustrate key concepts in both time series and Bayesian modeling.\n",
        "\n",
        "Working with Stan brought its share of challenges, such as convergence issues and visualizing posterior samples effectively. Although sometimes frustrating, these challenges reinforced my foundations in computational and applied mathematics. Practical drawbacks also arose—frequent installation issues on Mac and Windows, for instance. To streamline the process, I’m developing this notebook in Google Colab, where Stan is readily accessible, though installation remains somewhat slow."
      ],
      "metadata": {
        "id": "Nu-dy9MXbRw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Set-Up <a name=\"setup\"></a>"
      ],
      "metadata": {
        "id": "lFuMTxbzXW5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "options(warn=-1)\n",
        "\n",
        "# need to install the forecast package before rstan to avoid erros\n",
        "suppressMessages(install.packages(\"forecast\"))\n",
        "# to install Stan first need to install the V8 package via the command line\n",
        "system('sudo apt-get install -y libv8-dev')\n",
        "# then install rstan in R folder on the Google server (see lib parameter)\n",
        "suppressMessages(install.packages(\"rstan\", dependencies = T, repos = \"https://cloud.r-project.org\", lib = \"/usr/lib/R/library\",))\n",
        "suppressMessages(install.packages(\"tidyr\"))\n",
        "\n",
        "# load libraries\n",
        "suppressPackageStartupMessages(library(forecast))\n",
        "suppressPackageStartupMessages(library(rstan))\n",
        "suppressPackageStartupMessages(library(tidyr))\n",
        "suppressPackageStartupMessages(library(ggplot2))\n",
        "suppressPackageStartupMessages(library(stats))\n",
        "suppressPackageStartupMessages(library(lmtest))\n",
        "\n",
        "# stan options\n",
        "options(mc.cores = parallel::detectCores())\n",
        "rstan_options(auto_write = TRUE)\n",
        "\n",
        "# plot options\n",
        "options(repr.plot.width=20, repr.plot.height = 20, repr.plot.height=5)\n",
        "\n",
        "# download helpful files and unzip\n",
        "download.file(\"https://github.com/laurauguc/bayesian_time_series/raw/refs/heads/main/stan_models.zip\", destfile = 'bayesian_time_series.zip')\n",
        "unzip(\"bayesian_time_series.zip\")\n",
        "download.file(\"https://github.com/laurauguc/bayesian_time_series/raw/refs/heads/main/utils.R\", destfile = \"utils.R\")\n",
        "\n",
        "# source utils and set seed\n",
        "#source(\"utils.R\")\n",
        "set.seed(123) # For reproducibility"
      ],
      "metadata": {
        "id": "kHb0DFdRmbXT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian ARIMA function\n",
        "bayesian_arima <- function(x, order, h) {\n",
        "  d <- order[2]\n",
        "  if (d > 0) {\n",
        "    x_diff <- difference(x, d)\n",
        "    stan_data <- list(num_obs = length(x_diff), y = x_diff, p = order[1], q = order[3], h = h)\n",
        "  } else {\n",
        "    stan_data <- list(num_obs = length(x), y = x, p = order[1], q = order[3], h = h)\n",
        "  }\n",
        "  stan_fit <- rstan::stan(file = 'stan_models/ARMA_simple.stan', data = stan_data)\n",
        "  return(stan_fit)\n",
        "}\n",
        "\n",
        "# Reverse differencing helper function\n",
        "reverse_differencing <- function(y, x_observed, d) {\n",
        "  if (d > 0) {\n",
        "    for (i in d:1) {\n",
        "      x_observed_diff <- difference(x_observed, i - 1)\n",
        "      y <- y + x_observed_diff[length(x_observed_diff)]\n",
        "    }\n",
        "  }\n",
        "  return(y)\n",
        "}\n",
        "\n",
        "# Obtain mean predictions from Bayesian fit\n",
        "obtain_mean_pred <- function(bayesian_fit, x_observed, d, h) {\n",
        "  y_fit <- rstan::extract(bayesian_fit, 'y_fit')$y_fit\n",
        "  y_pred <- rstan::extract(bayesian_fit, 'y_pred')$y_pred\n",
        "\n",
        "  if (d > 0) {\n",
        "    y_fit <- reverse_differencing(y_fit, x_observed, d)\n",
        "    y_pred <- reverse_differencing(y_pred, x_observed, d)\n",
        "  }\n",
        "\n",
        "  y_pred_mean <- colMeans(cbind(y_fit, y_pred))\n",
        "  return(y_pred_mean)\n",
        "}\n",
        "\n",
        "# Comparison plot function for frequentist and Bayesian predictions\n",
        "comparison_plot <- function(frequentist_fit, bayesian_fit, x_observed, x_future) {\n",
        "  h <- length(x_future)\n",
        "  size <- length(x_observed) + h\n",
        "  d <- length(frequentist_fit[[\"model\"]][[\"Delta\"]])\n",
        "  x <- c(x_observed, x_future)\n",
        "\n",
        "  # Frequentist predictions\n",
        "  frequentist_y_fit <- c(fitted(frequentist_fit), rep(NA, h))\n",
        "  frequentist_pred <- predict(frequentist_fit, n.ahead = h)\n",
        "  frequentist_y_forecast <- c(rep(NA, size - h), frequentist_pred$pred)\n",
        "  frequentist_pred_interval <- forecast(frequentist_fit, h = h, level = 90)\n",
        "  frequentist_ub <- c(fitted(frequentist_fit) + 1.64 * sqrt(frequentist_fit$sigma2),\n",
        "                      frequentist_pred_interval[[\"upper\"]])\n",
        "  frequentist_lb <- c(fitted(frequentist_fit) - 1.64 * sqrt(frequentist_fit$sigma2),\n",
        "                      frequentist_pred_interval[[\"lower\"]])\n",
        "\n",
        "  # Bayesian predictions\n",
        "  y_pred_mean <- obtain_mean_pred(bayesian_fit, x_observed, d, h)\n",
        "  y_fit_mean <- replace(y_pred_mean, (size - h + 1):length(y_pred_mean), NA)\n",
        "  y_forecast_mean <- replace(y_pred_mean, 1:(size - h), NA)\n",
        "\n",
        "  # Bayesian credible intervals\n",
        "  y_fit <- rstan::extract(bayesian_fit, 'y_fit')$y_fit\n",
        "  y_pred <- rstan::extract(bayesian_fit, 'y_pred')$y_pred\n",
        "  y_pred_sims <- cbind(y_fit, y_pred)\n",
        "  y_pred_lb <- apply(y_pred_sims, 2, function(x) quantile(x, probs = 0.05))\n",
        "  y_pred_ub <- apply(y_pred_sims, 2, function(x) quantile(x, probs = 0.95))\n",
        "\n",
        "  # Plot\n",
        "  p <- ggplot(mapping = aes(x = 1:size)) +\n",
        "    geom_ribbon(aes(ymin = y_pred_lb, ymax = y_pred_ub, fill = \"Bayesian credible interval\"), alpha = 0.2) +\n",
        "    geom_ribbon(aes(ymin = frequentist_lb, ymax = frequentist_ub, fill = \"Frequentist prediction interval\"), alpha = 0.2) +\n",
        "    geom_line(aes(y = y_fit_mean, linetype = \"In-sample (Fitted values)\", color = \"Bayesian\")) +\n",
        "    geom_line(aes(y = y_forecast_mean, linetype = \"Out-of-sample (Forecasted values)\", color = \"Bayesian\")) +\n",
        "    geom_line(aes(y = frequentist_y_fit, linetype = \"In-sample (Fitted values)\", color = \"Frequentist\")) +\n",
        "    geom_line(aes(y = frequentist_y_forecast, linetype = \"Out-of-sample (Forecasted values)\", color = \"Frequentist\")) +\n",
        "    geom_point(aes(y = x_observed, x = 1:(size - h), shape = 'Training')) +\n",
        "    geom_point(aes(y = x_future, x = (size - h + 1):size, shape = 'Testing')) +\n",
        "    xlab(\"Simulation #\") + ylab(\"Value\") +\n",
        "    scale_fill_manual(name = \"90% Interval\", values = c(\"Bayesian credible interval\" = \"blue\", \"Frequentist prediction interval\" = \"orange\")) +\n",
        "    scale_shape_manual(name = \"Simulated datasets\", values = c(\"Training\" = 20, \"Testing\" = 21)) +\n",
        "    scale_linetype_manual(name = \"Prediction type\", values = c(\"solid\", \"dashed\")) +\n",
        "    scale_colour_manual(name = \"Statistical paradigm\", values = c(\"blue\", \"orange\"))\n",
        "\n",
        "  return(p)\n",
        "}\n",
        "\n",
        "obtain_mean_pred <- function(bayesian_fit, x, d, h) {\n",
        "  # Extract dimensions of parameters\n",
        "  p <- bayesian_fit@par_dims[[\"phi\"]]\n",
        "  q <- bayesian_fit@par_dims[[\"theta\"]]\n",
        "\n",
        "  # Extract posterior samples for sigma, phi, and theta\n",
        "  sigma_sims <- rstan::extract(bayesian_fit, \"sigma\")$sigma\n",
        "  phi_sims_mean <- if (p) apply(rstan::extract(bayesian_fit, \"phi\")$phi, 2, mean) else NULL\n",
        "  theta_sims_mean <- if (q) apply(rstan::extract(bayesian_fit, \"theta\")$theta, 2, mean) else NULL\n",
        "\n",
        "  # Apply differencing if needed\n",
        "  x_orig <- x\n",
        "  if (d) x <- difference(x, d)\n",
        "  T <- length(x)\n",
        "\n",
        "  # Initialize fitted values and errors\n",
        "  x_fit_mean <- numeric(T)\n",
        "  err_mean <- numeric(T)\n",
        "\n",
        "  # Generate in-sample fitted values\n",
        "  for (t in 2:T) {\n",
        "    eta <- 0\n",
        "    if (p) for (i in 1:min(p, t - 1)) eta <- eta + x[t - i] * phi_sims_mean[i]\n",
        "    if (q) for (i in 1:min(q, t - 1)) eta <- eta + err_mean[t - i] * theta_sims_mean[i]\n",
        "    x_fit_mean[t] <- eta\n",
        "    err_mean[t] <- x[t] - x_fit_mean[t]\n",
        "  }\n",
        "\n",
        "  # Reverse differencing for in-sample fitted values\n",
        "  if (d) {\n",
        "    for (i in seq_len(d)) {\n",
        "      x_above <- difference(x_orig, i - 1)\n",
        "      x_fit_mean <- reverse_diff_other_vector(x_fit_mean, x_above)\n",
        "    }\n",
        "  }\n",
        "\n",
        "  # Forecast future values\n",
        "  x_forecast_mean <- numeric(h)\n",
        "  for (t in seq_len(h)) {\n",
        "    eta <- 0\n",
        "    if (p) {\n",
        "      p_new <- min(t - 1, p)\n",
        "      p_rem <- p - p_new\n",
        "      for (i in seq_len(p_new)) eta <- eta + x_forecast_mean[t - i] * phi_sims_mean[i]\n",
        "      for (i in seq_len(p_rem)) eta <- eta + x[T + 1 - i] * phi_sims_mean[i + p_new]\n",
        "    }\n",
        "    if (q) {\n",
        "      q_rem <- q - min(t - 1, q)\n",
        "      for (i in seq_len(q_rem)) eta <- eta + err_mean[T + 1 - i] * theta_sims_mean[i]\n",
        "    }\n",
        "    x_forecast_mean[t] <- eta\n",
        "  }\n",
        "\n",
        "  # Reverse differencing for forecast values\n",
        "  if (d) {\n",
        "    for (i in seq_len(d)) {\n",
        "      x_above <- difference(x_orig, i - 1)\n",
        "      x_forecast_mean <- reverse_diff_forecast_mean(x_forecast_mean, x_above[length(x_above)])\n",
        "    }\n",
        "  }\n",
        "\n",
        "  # Combine in-sample fitted values and forecasted values\n",
        "  y_pred_mean <- c(x_fit_mean, x_forecast_mean)\n",
        "  return(y_pred_mean)\n",
        "}\n",
        "\n",
        "# Differencing and Reverse Differencing Functions\n",
        "\n",
        "difference <- function(x, d) {\n",
        "  for (i in seq_len(d)) x <- diff(x)\n",
        "  return(x)\n",
        "}\n",
        "\n",
        "reverse_diff_forecast_mean <- function(x_diff, init_value) {\n",
        "  x_diff[1] <- x_diff[1] + init_value\n",
        "  return(cumsum(x_diff))\n",
        "}\n",
        "\n",
        "reverse_diff_other_vector <- function(x_diff_fit, x_actual) {\n",
        "  return(cumsum(c(x_actual[1], x_diff_fit)) + c(x_actual[1], x_actual[-length(x_actual)]))\n",
        "}\n",
        "\n",
        "reverse_differencing_y_fit <- function(y_fit, y) {\n",
        "  y_fit <- sweep(cbind(rep_len(0, nrow(y_fit)), y_fit), 2, c(y[1], y[-length(y)]), \"+\")\n",
        "  return(y_fit)\n",
        "}\n",
        "\n",
        "reverse_differencing_y_forecast <- function(y_pred, y) {\n",
        "  y_pred[, 1] <- y_pred[, 1] + y[length(y)]\n",
        "  for (i in 2:ncol(y_pred)) y_pred[, i] <- y_pred[, i] + y_pred[, i - 1]\n",
        "  return(y_pred)\n",
        "}"
      ],
      "metadata": {
        "id": "ufq0vBLskJ-A"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Background <a name=\"background\"></a>\n",
        "\n",
        "### Bayesian vs. Frequentist Paradigms in Statistics\n",
        "\n",
        "Statistics typically follows two paradigms: **frequentist** and **Bayesian**. While most introductory courses focus on the frequentist approach, Bayesian statistics, dating back to the 1700s, has gained traction with advancements in computational power. These advancements allow us to solve complex integrals without analytical solutions, enabling custom Bayesian models—one of the paradigm's main advantages. The key distinction between these approaches lies in how each interprets probability.\n",
        "\n",
        "- **Frequentist Interpretation:** Probability represents the relative frequency of an event in repeated trials.\n",
        "- **Bayesian Interpretation:** Probability represents a degree of belief, making it a more intuitive approach for certain applications.\n",
        "\n",
        "This seemingly innocuous fundamental difference results in vastly different model-building approaches and interpretation of results.\n",
        "\n",
        "For example, Bayesian statisticians use probability distributions to describe a wide range of values, including model parameters like $\\alpha$ in $y = \\alpha + \\beta x$. In contrast, frequentists treat parameters as fixed values and only model the data generation process probabilistically. Frequentist inference typically relies on hypothesis testing, while Bayesian inference expresses uncertainty with probability distributions.\n",
        "\n",
        "Some additional differences include:\n",
        "\n",
        "- **Priors:** Bayesian models incorporate prior beliefs or expert knowledge, while this concept is foreign to frequentists.\n",
        "- **Hypothesis Testing vs. Uncertainty Estimation:** Frequentists use hypothesis tests, while Bayesians provide probability-based uncertainty.\n",
        "- **Model Customization:** Frequentists often rely on established hypothesis testing procedures, while Bayesian methods allow more flexibility by defining priors and likelihoods.\n",
        "\n",
        "Under specific conditions, such as with flat (uninformative) priors, Bayesian models can produce predictions similar to frequentist models. However, Bayesian models offer added flexibility through priors and customizability, making them particularly useful in cases with complex data generation processes.\n",
        "\n",
        "### What is Stan and Why Build Models with It?\n",
        "\n",
        "Stan is a probabilistic programming language widely used for Bayesian inference, particularly valuable in fields like biostatistics, epidemiology, and social sciences. Its robust algorithms—such as Hamiltonian Monte Carlo (HMC) and the No-U-Turn Sampler (NUTS)—enable efficient exploration of complex models. This flexibility makes Stan ideal for hierarchical modeling, time series analysis, and Gaussian processes, offering a transparent, reproducible environment for model development.\n",
        "\n",
        "Stan has been instrumental for me in two ways. First, it allows me to confirm my understanding of probabilistic models by defining their mathematical structures directly. Replicating a model in Stan is a rigorous test of both conceptual and technical mastery.\n",
        "\n",
        "Additionally, Stan’s flexibility facilitates building models tailored to specific applications where existing models fall short. For instance, Facebook’s Prophet model, popular for time series analysis, benefits from Stan’s ability to handle complex time-series dependencies. Starting with a known model, replicating it in Stan, and adjusting it as needed provides a powerful framework for addressing unique modeling needs.\n",
        "\n",
        "Helpful resources:\n",
        "- [Stan website](https://mc-stan.org/)\n",
        "- [Stan Introduction by Betancourt](https://betanalpha.github.io/assets/case_studies/stan_intro.html)\n",
        "\n",
        "### The ARIMA Model\n",
        "\n",
        "The Bayesian model we’ll build here is a Bayesian adaptation of the Autoregressive Integrated Moving Average (ARIMA) model, widely used for time series forecasting. Understanding the ARIMA model's underlying equations offers a solid foundation in time series analysis.\n",
        "\n",
        "The general ARIMA model is represented as:\n",
        "\n",
        "$$(1 - \\sum^p_{i=1}\\phi_iL^i)(1-L)^dX_t = (1+\\sum^q_{i=1}\\theta_i L^i) \\epsilon_t $$\n",
        "\n",
        "where \\( L \\) is the lag operator.\n",
        "\n",
        "The ARIMA model has two primary components:\n",
        "\n",
        "1) **Integration**: Transforming the series to stationarity through differencing, e.g., when $(d = 1)$, $((1-L)^dX_t)$ represents $( X_t - X_{t-1})$.\n",
        "   \n",
        "2) **ARMA Model**: Combining the autoregressive (AR) and moving average (MA) components.\n",
        "\n",
        "In this notebook, we build and evaluate a Bayesian ARIMA model by setting flat priors for comparability with the frequentist ARIMA model.\n",
        "\n",
        "# 4. Approach <a name=\"approach\"></a>\n",
        "\n",
        "The Bayesian ARIMA model is implemented in Stan and can be found here: `stan_models/ARIMA.stan`. This notebook documents the process of identifying and resolving modeling discrepancies until the Bayesian and frequentist results aligned.\n",
        "\n",
        "To facilitate comparison, we use flat priors in the Bayesian model, effectively “neutralizing” the prior’s influence. While this omits one of the Bayesian model’s advantages—the ability to include prior information—it confirms the model’s specification. We then consider adding priors as an extension.\n",
        "\n",
        "To identify and resolve discrepancies, I started with the simplest ARIMA model, the ARIMA(0,0,0) model, and progressively added complexity, until building a general ARIMA(p,d,q) model. The final Bayesian arima model that we'll be using (`stan_models/ARIMA.stan`) already reflects the resolved issues. Therefore, the results align with the `stats` library ARIMA model.\n",
        "\n",
        "For each progressively more complex ARIMA model, we perform the following steps:\n",
        "\n",
        "- Generate synthetic data with randomly chosen parameters\n",
        "- Use the `stats` package and Bayesian ARIMA to estimate these parameters independently\n",
        "- Compare and visualize results for consistency and insights\n",
        "\n",
        "# 5. Implementation <a name=\"implementation\"></a>"
      ],
      "metadata": {
        "id": "RVZ42KdZaRn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "size <- 1000\n",
        "h <- 200\n",
        "\n",
        "cat(\"Time series length: \", size, \"\\n\")\n",
        "cat(\"Forecasting horizon: \", h, \" (segmented off of the overall time series length) \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfMOZIS6iOX7",
        "outputId": "a4aca0e4-c9b3-48aa-c106-e2184e9c37ad"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time series length:  1000 \n",
            "Forecasting horizon:  200  (segmented off of the overall time series length) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process 1: White Noise = ARIMA(0,0,0)"
      ],
      "metadata": {
        "id": "6Ktjv3Ofh3_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a random time series and split into observed and future parts\n",
        "time_series <- rnorm(size)\n",
        "observed_data <- time_series[1:(size - h)]\n",
        "future_data <- time_series[(size - h + 1):size]\n",
        "\n",
        "# Set ARIMA model order\n",
        "model_order <- c(0, 0, 0)\n",
        "\n",
        "# Fit ARIMA model using frequentist and Bayesian methods\n",
        "frequentist_fit <- arima(x = observed_data, order = model_order, include.mean = FALSE)\n",
        "bayesian_fit <- bayesian_arima(x = observed_data, order = model_order, h = h)\n",
        "\n",
        "# Create comparison plot of the two fits\n",
        "p1 <- comparison_plot(frequentist_fit, bayesian_fit, observed_data, future_data)\n",
        "p1 + theme(text = element_text(size = 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "9l8wFAjNp8sK",
        "outputId": "911d6d4f-e3a0-41ff-9551-e1c9e770b180"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in eval(expr, envir) : \n",
            "  Exception: variable does not exist; processing stage=data initialization; variable name=T; base type=int (in 'anon_model', line 30, column 2 to column 17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "failed to create the sampler; sampling not done\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stan model 'anon_model' does not contain samples.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in if (p) apply(rstan::extract(bayesian_fit, \"phi\")$phi, 2, mean) else NULL: argument is of length zero\n",
          "traceback": [
            "Error in if (p) apply(rstan::extract(bayesian_fit, \"phi\")$phi, 2, mean) else NULL: argument is of length zero\nTraceback:\n",
            "1. obtain_mean_pred(bayesian_fit, x_observed, d, h)",
            "2. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = invokeRestart(\"eval_error\", \n .             cnd))\n . }, \"argument is of length zero\", base::quote(if (p) apply(rstan::extract(bayesian_fit, \n .     \"phi\")$phi, 2, mean) else NULL))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TK: Note on working with samples."
      ],
      "metadata": {
        "id": "Mz3w6LtFwYCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process 2: Auto Regressive 1 = ARIMA(1,0,0)"
      ],
      "metadata": {
        "id": "50uvfwETixT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "phi <- 0.7\n",
        "order <- c(1, 0, 0)\n",
        "\n",
        "# Generate AR(1) process\n",
        "errors <- rnorm(size, mean = 0, sd = 1)\n",
        "x <- numeric(size)\n",
        "x[1] <- 0  # Initial value\n",
        "for (i in 2:size) {\n",
        "  x[i] <- phi * x[i - 1] + errors[i]\n",
        "}\n",
        "\n",
        "# Split observed and future values\n",
        "x_observed <- head(x, size - h)\n",
        "x_future <- tail(x, h)\n",
        "\n",
        "# Fit ARIMA models\n",
        "frequentist_fit <- arima(x = x_observed, order = order, include.mean = FALSE)\n",
        "bayesian_fit <- bayesian_arima(x = x_observed, order = order, h = h)\n",
        "\n",
        "# Generate comparison plot\n",
        "p1 <- comparison_plot(frequentist_fit, bayesian_fit, x_observed, x_future)\n",
        "p1 + theme(text = element_text(size = 20))"
      ],
      "metadata": {
        "id": "f9XUXou9iw_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model comparison\n",
        "fb_label <- c(\"Frequentist\", \"Bayesian\")\n",
        "phi1_recov_f <- frequentist_fit$coef[[\"ar1\"]]\n",
        "phi1_recov_b <- apply(rstan::extract(bayesian_fit, \"phi\")$phi, 2, mean)[1]\n",
        "\n",
        "# Compute the closest model\n",
        "closest_model <- fb_label[which.min(c(abs(phi1_recov_f - phi), abs(phi1_recov_b - phi)))]\n",
        "\n",
        "cat(\"Phi parameter comparison\\n\")\n",
        "cat(\"Actual: \", phi, \"\\n\")\n",
        "cat(\"Recovered by Bayesian model: \", round(phi1_recov_b, 3), \"\\n\")\n",
        "cat(\"Recovered by Frequentist model: \", round(phi1_recov_f, 3), \"\\n\")\n",
        "cat(\"Closest Model: \", closest_model, \"\\n\")"
      ],
      "metadata": {
        "id": "Ug_2S15ziwN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(bayesian_fit, pars = c('phi', 'sigma'))"
      ],
      "metadata": {
        "id": "uhNBKlXXuXST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coeftest(frequentist_fit)"
      ],
      "metadata": {
        "id": "bPC1MZ3qwJf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TK: note on credible intervals vs confidence interval."
      ],
      "metadata": {
        "id": "OKX5eWgQwKe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process 3: Random Walk = ARIMA(0,1,0) = ARIMA(1,0,0) with $\\phi = 1$\n",
        "\n",
        "Data generating process: $x_t = x_{t-1} + \\epsilon$, where $\\epsilon \\sim \\text{Normal}(0,1)$. This is a special case of the ARIMA. Specifically, it corresponds to ARIMA(0,1,0), or, equivalently to an ARIMA(1,0,0) process with unit root, $\\phi_1 = 1$.)"
      ],
      "metadata": {
        "id": "C71OVo3chcWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "phi <- 1\n",
        "order <- c(1, 0, 0)\n",
        "\n",
        "# Generate AR(1) process\n",
        "errors <- rnorm(size, mean = 0, sd = 1)\n",
        "x <- numeric(size)\n",
        "x[1] <- 0  # Initial value for the AR process\n",
        "\n",
        "# Generate the AR(1) process values\n",
        "for (i in 2:size) {\n",
        "  x[i] <- phi * x[i - 1] + errors[i]\n",
        "}\n",
        "\n",
        "# Split observed and future values\n",
        "x_observed <- head(x, size - h)\n",
        "x_future <- tail(x, h)\n",
        "\n",
        "# Fit ARIMA models\n",
        "frequentist_fit <- arima(x = x_observed, order = order, include.mean = FALSE)\n",
        "bayesian_fit <- bayesian_arima(x = x_observed, order = order, h = h)\n",
        "\n",
        "# Generate comparison plot\n",
        "p1 <- comparison_plot(frequentist_fit, bayesian_fit, x_observed, x_future)\n",
        "p1 + theme(text = element_text(size = 20))"
      ],
      "metadata": {
        "id": "6FTHEEoVxA3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters comparison\n",
        "fb_label <- c(\"Frequentist\", \"Bayesian\")\n",
        "phi1_recov_f <- frequentist_fit$coef[[\"ar1\"]]\n",
        "phi1_recov_b <- apply(rstan::extract(bayesian_fit, \"phi\")$phi, 2, mean)[1]\n",
        "\n",
        "# Compute the closest model\n",
        "closest_model <- fb_label[which.min(c(abs(phi1_recov_f - phi), abs(phi1_recov_b - phi)))]\n",
        "\n",
        "cat(\"Phi parameter comparison\\n\")\n",
        "cat(\"Actual: \", phi, \"\\n\")\n",
        "cat(\"Recovered by Bayesian model: \", round(phi1_recov_b, 3), \"\\n\")\n",
        "cat(\"Recovered by Frequentist model: \", round(phi1_recov_f, 3), \"\\n\")\n",
        "cat(\"Closest Model: \", closest_model, \"\\n\")"
      ],
      "metadata": {
        "id": "z_orYt8nxGnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process 4: Moving Average Model = ARIMA(0,0,1)"
      ],
      "metadata": {
        "id": "Idw6AHQLyIFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "theta <- 0.2  # MA coefficient\n",
        "order <- c(0, 0, 1)  # ARIMA(0, 0, 1) model\n",
        "\n",
        "# Preallocate memory for x and error\n",
        "x <- numeric(size)\n",
        "error <- rnorm(size, mean = 0, sd = 1)\n",
        "\n",
        "# Generate the MA(1) process\n",
        "for (i in 2:size) {\n",
        "  x[i] <- error[i - 1] * theta + error[i]\n",
        "}\n",
        "\n",
        "# Split the data into observed and future values\n",
        "x_observed <- x[1:(size - h)]\n",
        "x_future <- x[(size - h + 1):size]\n",
        "\n",
        "# Fit ARIMA models\n",
        "frequentist_fit <- arima(x = x_observed, order = order, include.mean = FALSE)\n",
        "bayesian_fit <- bayesian_arima(x = x_observed, order = order, h = h)\n",
        "\n",
        "# Generate comparison plot\n",
        "p1 <- comparison_plot(frequentist_fit, bayesian_fit, x_observed, x_future)\n",
        "p1 + theme(text = element_text(size = 20))\n"
      ],
      "metadata": {
        "id": "8bhh5OtGyH8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process 5: ARIMA(0,2,0)"
      ],
      "metadata": {
        "id": "OqiBfIBzbkpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "order <- c(0, 2, 0)  # ARIMA(0, 2, 0) model\n",
        "\n",
        "# Preallocate vectors\n",
        "x <- numeric(size)\n",
        "x1 <- numeric(size)\n",
        "x2 <- rnorm(size, mean = 0, sd = 1)  # Generate all error terms at once\n",
        "\n",
        "# Generate the integrated process\n",
        "for (i in 2:size) {\n",
        "  x1[i] <- x1[i - 1] + x2[i]      # First difference\n",
        "  x[i] <- x[i - 1] + x1[i]         # Second difference\n",
        "}\n",
        "\n",
        "# Split the data into observed and future values\n",
        "x_observed <- x[1:(size - h)]\n",
        "x_future <- x[(size - h + 1):size]\n",
        "\n",
        "# Fit ARIMA models\n",
        "frequentist_fit <- arima(x = x_observed, order = order, include.mean = FALSE)\n",
        "bayesian_fit <- bayesian_arima(x = x_observed, order = order, h = h)\n",
        "\n",
        "# Generate comparison plot\n",
        "p1 <- comparison_plot(frequentist_fit, bayesian_fit, x_observed, x_future)\n",
        "p1 + theme(text = element_text(size = 20))"
      ],
      "metadata": {
        "id": "pN0DDOv8bkRr",
        "outputId": "857d8516-d6ab-4aa5-b0a6-698e47a3f6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in eval(expr, envir) : \n",
            "  Exception: variable does not exist; processing stage=data initialization; variable name=T; base type=int (in 'anon_model', line 30, column 2 to column 17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "failed to create the sampler; sampling not done\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stan model 'anon_model' does not contain samples.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in if (p) apply(rstan::extract(bayesian_fit, \"phi\")$phi, 2, mean) else NULL: argument is of length zero\n",
          "traceback": [
            "Error in if (p) apply(rstan::extract(bayesian_fit, \"phi\")$phi, 2, mean) else NULL: argument is of length zero\nTraceback:\n",
            "1. obtain_mean_pred(bayesian_fit, x_observed, d, h)",
            "2. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = invokeRestart(\"eval_error\", \n .             cnd))\n . }, \"argument is of length zero\", base::quote(if (p) apply(rstan::extract(bayesian_fit, \n .     \"phi\")$phi, 2, mean) else NULL))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Conclusion <a name=\"conclusion\"></a>\n",
        "\n",
        "### To do/TK: clarifications about the forecast model being used for forecasting the uncertainty of the stats arima model. This makes it inherently bayesian.\n",
        "\n",
        "\n",
        "###To do: You can see the stan file to see how the mathematical equations are specified, and the _____ function for additional data preparation transformation."
      ],
      "metadata": {
        "id": "Xr_vhmWKaRdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next steps:\n",
        "\n"
      ],
      "metadata": {
        "id": "WmwQMPIS8acG"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMg/8VVQfQnwY+RmIosRwhe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}